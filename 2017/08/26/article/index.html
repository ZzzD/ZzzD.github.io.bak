<!DOCTYPE html>
<html lang="">
  <head>
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="线性回归和逻辑回归详解 ——机器学习"/>




  <meta name="keywords" content="machine learning," />





  <link rel="alternate" href="/default" title="理想国">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="http://superz.me/2017/08/26/article/"/>


<meta name="description" content="前言经典的线性回归(Linear Regression)模型和逻辑回归(Logistic Regression)模型，是机器学习领域的经典算法，也是理解其它更复杂机器学习模型的基础，本文不涉及具体编程语言的实现，只探究算法的数学意义。 理解本文，读者需具备基础的微积分、线性代数和统计学知识。">
<meta name="keywords" content="machine learning">
<meta property="og:type" content="article">
<meta property="og:title" content="线性回归和逻辑回归详解 ——机器学习">
<meta property="og:url" content="http://superz.me/2017/08/26/article/index.html">
<meta property="og:site_name" content="理想国">
<meta property="og:description" content="前言经典的线性回归(Linear Regression)模型和逻辑回归(Logistic Regression)模型，是机器学习领域的经典算法，也是理解其它更复杂机器学习模型的基础，本文不涉及具体编程语言的实现，只探究算法的数学意义。 理解本文，读者需具备基础的微积分、线性代数和统计学知识。">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2017-08-26T15:26:57.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="线性回归和逻辑回归详解 ——机器学习">
<meta name="twitter:description" content="前言经典的线性回归(Linear Regression)模型和逻辑回归(Logistic Regression)模型，是机器学习领域的经典算法，也是理解其它更复杂机器学习模型的基础，本文不涉及具体编程语言的实现，只探究算法的数学意义。 理解本文，读者需具备基础的微积分、线性代数和统计学知识。">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>


  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />




<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: true
    },
  };
</script>




  



    <title> 线性回归和逻辑回归详解 ——机器学习 - 理想国 </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  </head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">理想国</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          线性回归和逻辑回归详解 ——机器学习
        
      </h1>

      <time class="post-time">
          Aug 26 2017
      </time>
    </header>



    
            <div class="post-content">
            <hr>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>经典的线性回归(<em>Linear Regression</em>)模型和逻辑回归(<em>Logistic Regression</em>)模型，是机器学习领域的经典算法，也是理解其它更复杂机器学习模型的基础，本文不涉及具体编程语言的实现，只探究算法的数学意义。</p>
<p>理解本文，读者需具备基础的微积分、线性代数和统计学知识。</p>
<a id="more"></a>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="什么是线性回归"><a href="#什么是线性回归" class="headerlink" title="什么是线性回归"></a>什么是线性回归</h3><p>先上wikipedia定义：</p>
<blockquote>
<p>在统计学中，<strong>线性回归（Linear regression）</strong>是利用称为线性回归方程的<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="external">最小二乘</a>函数对一个或多个<a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E5%8F%98%E9%87%8F" target="_blank" rel="external">自变量</a>和<a href="https://zh.wikipedia.org/w/index.php?title=%E5%9B%A0%E5%8F%98%E9%87%8F&amp;action=edit&amp;redlink=1" target="_blank" rel="external">因变量</a>之间关系进行建模的一种<a href="https://zh.wikipedia.org/wiki/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90" target="_blank" rel="external">回归分析</a>。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归，大于一个自变量情况的叫做多元回归。</p>
</blockquote>
<p>首先应该明了的是，线性回归其实是数学概念，不是计算机科学概念。在被运用到机器学习领域前，线性回归就已经被广泛使用。</p>
<p>线性，体现为一次方程，下面利用例子说明。</p>
<p>现有某区域内历史房产销售数据集:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Size(平米)</th>
<th style="text-align:center">Price(￥) in 10,000’s</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">210</td>
<td style="text-align:center">460</td>
</tr>
<tr>
<td style="text-align:center">141</td>
<td style="text-align:center">232</td>
</tr>
<tr>
<td style="text-align:center">153</td>
<td style="text-align:center">315</td>
</tr>
<tr>
<td style="text-align:center">85</td>
<td style="text-align:center">178</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
</tbody>
</table>
<p>需根据该历史数据评估该区域内其它房产的价值，为了得到最简单的情况，假设房产价值只与房屋面积相关(<em>single feature</em>的情况下，即在平面坐标系上找出一条和该数据集最匹配的直线)，即$\theta_0 + \theta_1x=y$, 该式可写作：<br>$$<br>\theta_0x_0 + \theta_1x_1=y\ \ \ (式2)\\(令x_0 = 1)<br>$$</p>
<p>上式被称为<em>Hypothesis Function</em>，记为$h_\theta(x)$</p>
<p>代入数据集，得：<br>$$<br>\theta_0 + 85\theta_1 = 178\\\theta_0 + 210\theta_1 = 460\\\theta_0 + 141\theta_1 = 232\\\theta_0 + 153\theta_1 = 315\\…\\(式3)<br>$$</p>
<p>观察式2、式3，令：<br>$$<br>X= \begin{bmatrix}1 &amp; 210\\1 &amp; 141\\1 &amp; 153\\1 &amp; 85\\1 &amp; …\\1 &amp; x_1^{(j)}\end{bmatrix}\ \ \ \ \ \ \ \ \ \ \ \ \ y=\begin{bmatrix}460\\232\\315\\178\\…\\y^{(j)}\end{bmatrix}<br>$$<br>上标<sup>(j)</sup>表示第j个样本，即X, y中第j行元素</p>
<p>根据<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="external">最小二乘法</a>原理，现定义：<br>$$<br>J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2\ \ \ (式4)\\(m为样本数)<br>$$</p>
<p>要使式1尽可能的拟合该数据集，即$goal: minimize\ J(\theta_0,\ \theta_1)$</p>
<p>其中 <em>J</em> 被称为<em>Cost Function</em>，根据式3，<strong>线性回归，即为求解θ，使得Cost Function最小的问题</strong></p>
<p>因此，把输入映射到输出的问题就化为了一个找到一个能产生最小误差的函数的最佳化问题。</p>
<h3 id="Minimize-Cost-Function"><a href="#Minimize-Cost-Function" class="headerlink" title="Minimize Cost Function"></a>Minimize Cost Function</h3><p>（吐槽: 第一次看到“最小二乘法”这个名词时，不明觉厉的高大上，其实翻译为“最小方差法“比较好，即所有样本预测值与实际值差值的平方之和）</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (val, i) <span class="keyword">in</span> a &#123;</div><div class="line">    <span class="keyword">let</span> adf = fa</div><div class="line">&#125;</div></pre></td></tr></table></figure>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/machine-learning/">machine learning</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
    2017
    <a class="footer-author">&#x2764;  ZzzD.</a>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

  </body>
</html>
